# elevenlabs_handler.py
import os
import logging
import numpy as np
from rich.console import Console
from baseHandler import BaseHandler

from elevenlabs.client import ElevenLabs  # pip install elevenlabs

logging.basicConfig(format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)
console = Console()


class ElevenLabsTTSHandler(BaseHandler):
    """
    Drop-in replacement for ChatTTSHandler that uses ElevenLabs TTS.

    - Streams PCM 16 kHz (S16LE) audio so no resampling needed.
    - Yields fixed-size np.int16 chunks of length `chunk_size`.
    - Supports streaming and non-streaming modes, like your original.

    Config via gen_kwargs:
      - api_key (str, optional)         : falls back to ELEVENLABS_API_KEY env
      - base_url (str, optional)        : default "https://api.elevenlabs.io"
      - voice_id (str, optional)        : default from ELEVENLABS_VOICE_ID or a public voice
      - model_id (str, optional)        : default "eleven_multilingual_v2"
      - output_format (str, optional)   : default "pcm_16000"
      - warmup_text (str, optional)     : small text to preflight the API (None to skip)
    """

    def setup(
        self,
        should_listen,
        device="cpu",        # device is irrelevant for remote TTS, kept for API parity
        gen_kwargs=None,
        stream=True,
        chunk_size=512,
    ):
        self.should_listen = should_listen
        self.device = device
        self.stream = stream
        self.chunk_size = int(chunk_size)

        gen_kwargs = gen_kwargs or {}
        api_key = gen_kwargs.get("api_key") or os.getenv("ELEVENLABS_API_KEY") or ""
        base_url = gen_kwargs.get("base_url", "https://api.elevenlabs.io")
        self.voice_id = gen_kwargs.get("voice_id") or os.getenv("ELEVENLABS_VOICE_ID") or "JBFqnCBsd6RMkjVDRZzb"
        self.model_id = gen_kwargs.get("model_id", "eleven_multilingual_v2")
        # IMPORTANT: request raw PCM 16k so we can yield int16 frames directly
        self.output_format = gen_kwargs.get("output_format", "pcm_16000")
        self.warmup_text = gen_kwargs.get("warmup_text", None)

        self.client = ElevenLabs(api_key=api_key, base_url=base_url)
        self.warmup()

    def warmup(self):
        """Optional tiny request to ensure credentials/network are good."""
        if not self.warmup_text:
            logger.info(f"Skipping warmup for {self.__class__.__name__}")
            return
        try:
            logger.info(f"Warming up {self.__class__.__name__}")
            # Non-streaming convert avoids keeping a stream open during warmup.
            _ = self.client.text_to_speech.convert(
                text=self.warmup_text,
                voice_id=self.voice_id,
                model_id=self.model_id,
                output_format=self.output_format,  # "pcm_16000"
            )
        except Exception as e:
            logger.warning(f"ElevenLabs warmup failed: {e}")

    def _yield_pcm_chunks(self, pcm_bytes: bytes):
        """Convert raw little-endian PCM bytes to int16 and yield fixed-size frames."""
        # Ensure even number of bytes (2 bytes per sample)
        if len(pcm_bytes) % 2:
            pcm_bytes += b"\x00"
        samples = np.frombuffer(pcm_bytes, dtype="<i2")  # little-endian int16
        for i in range(0, len(samples), self.chunk_size):
            frame = samples[i : i + self.chunk_size]
            if len(frame) < self.chunk_size:
                yield np.pad(frame, (0, self.chunk_size - len(frame)))
            else:
                yield frame

    def process(self, llm_sentence):
        console.print(f"[green]ASSISTANT: {llm_sentence}")

        if self.stream:
            # Stream raw bytes as theyâ€™re generated by ElevenLabs
            # We request output_format="pcm_16000" so chunks are already raw PCM at 16k.
            audio_stream = self.client.text_to_speech.stream(
                text=str(llm_sentence),
                voice_id=self.voice_id,
                model_id=self.model_id,
                output_format=self.output_format,  # "pcm_16000"
            )

            remainder = b""
            try:
                for chunk in audio_stream:
                    # SDK yields bytes (audio) and sometimes other events; keep only bytes.
                    if not isinstance(chunk, (bytes, bytearray)):
                        continue
                    data = remainder + bytes(chunk)
                    # keep even number of bytes; convert what we can, stash the rest
                    usable_len = (len(data) // 2) * 2
                    if usable_len:
                        yield from self._yield_pcm_chunks(data[:usable_len])
                    remainder = data[usable_len:]
            finally:
                # Flush any tail bytes
                if remainder:
                    yield from self._yield_pcm_chunks(remainder)
                self.should_listen.set()
        else:
            # One-shot generation; returns the full audio buffer
            audio_bytes = self.client.text_to_speech.convert(
                text=str(llm_sentence),
                voice_id=self.voice_id,
                model_id=self.model_id,
                output_format=self.output_format,  # "pcm_16000"
            )
            yield from self._yield_pcm_chunks(bytes(audio_bytes))
            self.should_listen.set()
